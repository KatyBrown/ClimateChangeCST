{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 745715,
     "status": "ok",
     "timestamp": 1597059699847,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "RPOPpqEXohJO",
    "outputId": "2e93d7ef-bec2-449d-e8dc-43634e396310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 972kB 2.6MB/s \n",
      "\u001b[K     |████████████████████████████████| 10.9MB 7.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 14.7MB 257kB/s \n",
      "\u001b[?25hReading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "Suggested packages:\n",
      "  libgdal-doc\n",
      "The following NEW packages will be installed:\n",
      "  libgeos-dev libproj-dev proj-bin\n",
      "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
      "Need to get 305 kB of archives.\n",
      "After this operation, 1,706 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgeos-dev amd64 3.6.2-1build2 [73.1 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libproj-dev amd64 4.9.3-2 [199 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 proj-bin amd64 4.9.3-2 [32.3 kB]\n",
      "Fetched 305 kB in 2s (153 kB/s)\n",
      "Selecting previously unselected package libgeos-dev.\n",
      "(Reading database ... 144487 files and directories currently installed.)\n",
      "Preparing to unpack .../libgeos-dev_3.6.2-1build2_amd64.deb ...\n",
      "Unpacking libgeos-dev (3.6.2-1build2) ...\n",
      "Selecting previously unselected package libproj-dev:amd64.\n",
      "Preparing to unpack .../libproj-dev_4.9.3-2_amd64.deb ...\n",
      "Unpacking libproj-dev:amd64 (4.9.3-2) ...\n",
      "Selecting previously unselected package proj-bin.\n",
      "Preparing to unpack .../proj-bin_4.9.3-2_amd64.deb ...\n",
      "Unpacking proj-bin (4.9.3-2) ...\n",
      "Setting up libproj-dev:amd64 (4.9.3-2) ...\n",
      "Setting up libgeos-dev (3.6.2-1build2) ...\n",
      "Setting up proj-bin (4.9.3-2) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "\u001b[K     |████████████████████████████████| 133.1MB 76kB/s \n",
      "\u001b[K     |████████████████████████████████| 225kB 2.8MB/s \n",
      "\u001b[?25h  Building wheel for basemap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pyshp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |████████████████████████████████| 18.2MB 1.2MB/s \n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "!pip install -q geopandas\n",
    "!apt install -q proj-bin libproj-dev libgeos-dev -y\n",
    "!pip install -q https://github.com/matplotlib/basemap/archive/master.zip\n",
    "!pip install -q rasterio\n",
    "\n",
    "# Pandas is a package containing additional functions to use data frames in Python\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import warnings\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "warnings.simplefilter('ignore')\n",
    "# These two lines allow the notebook to access the Google Drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# This is the path to the project folder within the Google Drive.\n",
    "file_path = \"/content/drive/My Drive/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 921,
     "status": "ok",
     "timestamp": 1597066892543,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "tdlS55otmsgh"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1018,
     "status": "ok",
     "timestamp": 1597066791072,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "agh9gxiuuUYX"
   },
   "outputs": [],
   "source": [
    "def convert_xy_to_longlat(grid_x, grid_y):\n",
    "  lon = ((grid_x / 6) - 180)\n",
    "  lat = -((grid_y / 6) - 90)\n",
    "  return (lon, lat)\n",
    "\n",
    "def convert_longlat_to_xy(lon, lat):\n",
    "  grid_x = int((lon + 180) * 6)\n",
    "  grid_y = int((-lat + 90) * 6)\n",
    "  return (grid_x, grid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xOgWTVyyS1iP"
   },
   "source": [
    "---\n",
    "## Notebook 11\n",
    "# WORLDCLIM Data - Extracting climate predictions for presence points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vAa3WT5S3bt"
   },
   "source": [
    "In this notebook we extract the measurements for the 19 worldclim variables for all points where species have been observed for each model-ssp-timepoint combination.\n",
    "\n",
    "For each species, we generate a table of the 19 measurements at each point for each of the 48 (3 models * 4 scenarios * 4 timepoints) predicted futures.\n",
    "\n",
    "The code is otherwise identical to the ```batch_data_presence_observed_all_species``` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 881,
     "status": "ok",
     "timestamp": 1597066798101,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "-2QCAMrQ7JHy"
   },
   "outputs": [],
   "source": [
    "bioclim = pd.read_csv(file_path + \"bioclim.tsv\", sep=\"\\t\")\n",
    "bioclim_name = dict(zip(bioclim['variable_number'], bioclim['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1597066798107,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "ZpmAO3SMLZO5"
   },
   "outputs": [],
   "source": [
    "models = ['BCC-CSM2-MR',\n",
    "         'CanESM5',\n",
    "         'MIROC6']\n",
    "scenarios = ['ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "\n",
    "time_periods = ['2021-2040', '2041-2060', '2061-2080', '2081-2100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHZZFP997JKB"
   },
   "outputs": [],
   "source": [
    "species_list = [line.strip() for line in open(file_path + \"species_names.tsv\")]\n",
    "for model in models:\n",
    "  if not os.path.exists(file_path + \"species_plus_climate_predicted/\" + model):\n",
    "    os.mkdir(file_path + \"species_plus_climate_predicted/\" + model)\n",
    "  for scenario in scenarios:\n",
    "    if not os.path.exists(file_path +\"species_plus_climate_predicted/\" + model + \"/\" + scenario):\n",
    "      os.mkdir(file_path + \"species_plus_climate_predicted/\" + model + \"/\" + scenario)\n",
    "    for time_period in time_periods:\n",
    "        if not os.path.exists(file_path +\"species_plus_climate_predicted/\" + model + \"/\" + scenario + \"/\" + time_period):\n",
    "          os.mkdir(file_path + \"species_plus_climate_predicted/\" + model + \"/\" + scenario + \"/\" + time_period)\n",
    "        # set the paths to the raster files for current and predicted climate\n",
    "        raster_path_current = file_path + \"climate_data/\" + model + \"/\" + scenario + \"/\" + time_period + \".tiff\"\n",
    "        # open the raster files\n",
    "        raster_current = rasterio.open(raster_path_current)\n",
    "\n",
    "        # convert the data into a matrix, round to 6dp, replace inf with nan\n",
    "        grid_current = raster_current.read()\n",
    "        grid_current = np.round(grid_current, 6)\n",
    "        grid_current[grid_current == float('-inf'), ] = float('nan')\n",
    "        # exclude very low latitudes\n",
    "        grid_current = grid_current[:, 0:930, :]\n",
    "\n",
    "        for species_name in species_list:\n",
    "            distribution_table = pd.read_csv(file_path + \"geo_filtered_main_tables/\" + species_name + \".csv\", sep=\"\\t\")\n",
    "            distribution_table['x_pos_raster'] = [convert_longlat_to_xy(x, 0)[0] for x in distribution_table['decimalLongitude']]\n",
    "            distribution_table['y_pos_raster'] = [convert_longlat_to_xy(0, y)[1] for y in distribution_table['decimalLatitude']]\n",
    "            distribution_table['ID'] = [species_name + \"_obs_\" +  str(x) for x in np.arange(1, len(distribution_table) + 1)]\n",
    "\n",
    "            obs_coord_dict = dict()\n",
    "            for obs_ID, x, y, g1, g2 in zip(distribution_table['ID'],\n",
    "                                            distribution_table['x_pos_raster'],\n",
    "                                            distribution_table['y_pos_raster'],\n",
    "                                            distribution_table['decimalLongitude'],\n",
    "                                            distribution_table['decimalLatitude']):\n",
    "              obs_coord_dict[obs_ID] = ((x, y, g1, g2))\n",
    "\n",
    "            raster_results = []\n",
    "\n",
    "            # for each observation\n",
    "            for obs_ID in obs_coord_dict:\n",
    "                # get the co-ordinates of the observation\n",
    "                x, y, g1, g2 = obs_coord_dict[obs_ID]\n",
    "\n",
    "                # make a list to store the results for this observation\n",
    "                this_obs = [obs_ID, x, y, g1, g2]\n",
    "                # for each bioclim variable\n",
    "                for i in range(0, 19):\n",
    "                    # get the grid for this variable\n",
    "                    var_grid = grid_current[i]\n",
    "                    \n",
    "                    # get the value of this variable at this grid point\n",
    "                    gridpoint_current = var_grid[y, x]\n",
    "                    print (gridpoint_current)\n",
    "                    # store the results for this observation\n",
    "                    this_obs.append(gridpoint_current)\n",
    "                  \n",
    "                raster_results.append(this_obs)\n",
    "\n",
    "            results = pd.DataFrame(raster_results, columns=['obs_ID', 'x', 'y', 'decimalLongitude', 'decimalLatitude'] + [bioclim_name[x] for x in range(1, 20)])\n",
    "            results.to_csv(file_path + \"species_plus_climate_predicted/\" + model + \"/\" + scenario + \"/\" + time_period + \"/\" + species_name + \"_observations.tsv\", sep=\"\\t\", index=None)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPkRQQlfkmI/AttUjRuVZHI",
   "collapsed_sections": [],
   "name": "11_batch_data_presence_predicted_all_species",
   "provenance": [
    {
     "file_id": "1_2Gt2xU_z4HZ7lc1cMesR8QnTWnjOO6U",
     "timestamp": 1597058897842
    },
    {
     "file_id": "1w6XYYH-Fg5eAHWEpZXC4uxBHu0gWeN0u",
     "timestamp": 1596820976994
    },
    {
     "file_id": "1rbf23z75cQEZK1cf1J6UzUjONwoNkqta",
     "timestamp": 1596820313739
    },
    {
     "file_id": "1CK3pembU63f-LIHil2CtJltp9GtwBr3y",
     "timestamp": 1596803598953
    },
    {
     "file_id": "1znoNo7JDrfelUOgAYtMYMZpa4T2OWLzt",
     "timestamp": 1596728531288
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
