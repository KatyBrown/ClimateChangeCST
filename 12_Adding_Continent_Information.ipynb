{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39172,
     "status": "ok",
     "timestamp": 1597063180038,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "RPOPpqEXohJO",
    "outputId": "e5ed248a-05d1-4056-9c67-0aecb77b94f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "libgeos-dev is already the newest version (3.6.2-1build2).\n",
      "libproj-dev is already the newest version (4.9.3-2).\n",
      "proj-bin is already the newest version (4.9.3-2).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
      "  Building wheel for basemap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Mounted at /content/drive\n",
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "!pip install -q geopandas\n",
    "!apt install -q proj-bin libproj-dev libgeos-dev -y\n",
    "!pip install -q https://github.com/matplotlib/basemap/archive/master.zip\n",
    "!pip install -q rasterio\n",
    "\n",
    "# Pandas is a package containing additional functions to use data frames in Python\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import warnings\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import shapely\n",
    "import os\n",
    "import copy\n",
    "warnings.simplefilter('ignore')\n",
    "# These two lines allow the notebook to access the Google Drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# This is the path to the project folder within the Google Drive.\n",
    "file_path = \"/content/drive/My Drive/\"\n",
    "\n",
    "%load_ext rpy2.ipython\n",
    "from rpy2.robjects import pandas2ri  # activate pandas R  interface\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "agh9gxiuuUYX"
   },
   "outputs": [],
   "source": [
    "def convert_xy_to_longlat(grid_x, grid_y):\n",
    "  lon = ((grid_x / 6) - 180)\n",
    "  lat = -((grid_y / 6) - 90)\n",
    "  return (lon, lat)\n",
    "\n",
    "def convert_longlat_to_xy(lon, lat):\n",
    "  grid_x = int((lon + 180) * 6)\n",
    "  grid_y = int((-lat + 90) * 6)\n",
    "  return (grid_x, grid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76aJVPvsucVA"
   },
   "source": [
    "---\n",
    "## Notebook 12\n",
    "# Adding Continent Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "68LcntweuQJ5"
   },
   "source": [
    "This notebook is just to add a \"continent\" column to the observation data and predicted data for the worldclim variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5zPxNKllw1zj"
   },
   "source": [
    "First, we read in a shapefile showing the location of each continent, so that we can automatically assign observation points to the correct continent - source https://www.arcgis.com/home/item.html?id=5cf4f223c4a642eb9aa7ae1216a04372"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGNWe2Lq7JES"
   },
   "outputs": [],
   "source": [
    "worldmap = gpd.read_file(file_path + \"/continent_shapefile/continent.shp\", index_col=0)\n",
    "worldmap = worldmap.to_crs('epsg:4088')\n",
    "worldmap = worldmap[worldmap['CONTINENT'] != 'Antarctica']\n",
    "worldmap.index = worldmap['CONTINENT']\n",
    "continents = dict(zip(worldmap['CONTINENT'], worldmap['geometry']))\n",
    "worldmap['geometry'] = worldmap['geometry'].simplify(tolerance=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1zfVVFDxGC8"
   },
   "source": [
    "We also read the list of species which we have observations for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-2QCAMrQ7JHy"
   },
   "outputs": [],
   "source": [
    "species_list = [line.strip() for line in open(file_path + \"species_names.tsv\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ijydHsJtGwlh"
   },
   "source": [
    "We want to know which continent each species is in - read the observation tables for each species then check if the point is within the polygon for each continent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0TZyA1kVP6ii"
   },
   "outputs": [],
   "source": [
    "species_type_obs = dict()\n",
    "gdfD = dict()\n",
    "for species in species_list:\n",
    "    if not os.path.exists(file_path + \"species_plus_climate_observed_geo/\" + species + \".tsv\"):\n",
    "      obs_table = pd.read_csv(file_path + \"species_plus_climate_observed/\" + species + \"_observations.tsv\", sep=\"\\t\")\n",
    "      if len(obs_table) != 0:\n",
    "          gdf = gpd.GeoDataFrame(obs_table,\n",
    "                                geometry=gpd.points_from_xy(obs_table['decimalLongitude'], obs_table['decimalLatitude']),\n",
    "                                crs=\"epsg:4326\")\n",
    "          gdf = gdf.to_crs('epsg:4088')\n",
    "          conts = []\n",
    "          this_cont = 0\n",
    "          for point in gdf['geometry']:\n",
    "            for continent in [\"North America\", \"Europe\", \"Asia\", \"South America\", \"Africa\", \"Australia\", \"Oceania\"]:\n",
    "                poly = continents[continent]\n",
    "                if point.within(poly):\n",
    "                  this_cont = continent\n",
    "                  conts.append(this_cont)\n",
    "                  break\n",
    "          gdf['Continent'] = conts\n",
    "          gdf.to_csv(file_path + \"species_plus_climate_observed_geo/\" + species + \".tsv\", sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1597067885678,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "8DfEHKN-ZlVE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP+IJd6Xi4arFKUKFZsXfh8",
   "collapsed_sections": [],
   "name": "12_get_continents.ipynb",
   "provenance": [
    {
     "file_id": "1w6XYYH-Fg5eAHWEpZXC4uxBHu0gWeN0u",
     "timestamp": 1597061050417
    },
    {
     "file_id": "1rbf23z75cQEZK1cf1J6UzUjONwoNkqta",
     "timestamp": 1596820313739
    },
    {
     "file_id": "1CK3pembU63f-LIHil2CtJltp9GtwBr3y",
     "timestamp": 1596803598953
    },
    {
     "file_id": "1znoNo7JDrfelUOgAYtMYMZpa4T2OWLzt",
     "timestamp": 1596728531288
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
