{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1590,
     "status": "ok",
     "timestamp": 1596110105704,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "_d_1WZWg2nCE",
    "outputId": "097e9e6d-780c-4449-9712-c79539ae4fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Pandas is a package containing additional functions to use data frames in Python\n",
    "import pandas as pd\n",
    "\n",
    "# These two lines allow the notebook to access the Google Drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# This is the path to the project folder within the Google Drive.\n",
    "file_path = \"/content/drive/My Drive/\"\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Notebook 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Suu258UHBAIC"
   },
   "source": [
    "# Data Cleaning - Automated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eud3QVCtMwnP"
   },
   "source": [
    "Now we can run the data cleaning steps on all the tables.  We can automate this by reading all the species names from a file (in our Drive as species_names.tsv) into a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 821,
     "status": "ok",
     "timestamp": 1596114331145,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "wmv00W4jA8lO"
   },
   "outputs": [],
   "source": [
    "species_list = [line.strip() for line in open(file_path + \"species_names.tsv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 985,
     "status": "ok",
     "timestamp": 1596114354487,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "FXt5rNHgMrPD",
    "outputId": "63c8e384-44f0-4bf0-fa06-0c06ff0aa14e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acromyrmex_echinatior',\n",
       " 'Amblyomma_americanum',\n",
       " 'Amblyomma_aureolatum',\n",
       " 'Amblyomma_sculptum',\n",
       " 'Apis_cerana',\n",
       " 'Apis_mellifera',\n",
       " 'Asobara_tabida',\n",
       " 'Athalia_rosae',\n",
       " 'Biorhiza_pallida',\n",
       " 'Bombus_terrestris',\n",
       " 'Camponotus_castaneus',\n",
       " 'Camponotus_floridanus',\n",
       " 'Camponotus_japonicus',\n",
       " 'Camponotus_ligniperdus',\n",
       " 'Cardiocondyla_obscurior',\n",
       " 'Cephus_cinctus',\n",
       " 'Ceratina_australensis',\n",
       " 'Cotesia_vestalis',\n",
       " 'Crematogaster_osakensis',\n",
       " 'Dermacentor_andersoni',\n",
       " 'Dermacentor_variabilis',\n",
       " 'Dinoponera_quadriceps',\n",
       " 'Exoneurella_tridentata',\n",
       " 'Fopius_arisanus',\n",
       " 'Halictus_scabiosae',\n",
       " 'Harpegnathos_saltator',\n",
       " 'Ixodes_persulcatus',\n",
       " 'Ixodes_ricinus',\n",
       " 'Ixodes_scapularis',\n",
       " 'Lasius_niger',\n",
       " 'Linepithema_humile',\n",
       " 'Lysiphlebus_fabarum',\n",
       " 'Megachile_rotundata',\n",
       " 'Megalopta_genalis',\n",
       " 'Megastigmus_spermotrophus',\n",
       " 'Messor_barbarus',\n",
       " 'Messor_capitatus',\n",
       " 'Messor_hellenius',\n",
       " 'Messor_structor',\n",
       " 'Microplitis_demolitor',\n",
       " 'Monomorium_pharaonis',\n",
       " 'Nasonia_giraulti',\n",
       " 'Nasonia_vitripennis',\n",
       " 'Neodiprion_lecontei',\n",
       " 'Ooceraea_biroi',\n",
       " 'Osmia_bicornis',\n",
       " 'Osmia_cornuta',\n",
       " 'Panonychus_citri',\n",
       " 'Pheidole_pallidula',\n",
       " 'Pogonomyrmex_barbatus',\n",
       " 'Pogonomyrmex_californicus',\n",
       " 'Polistes_canadensis',\n",
       " 'Polistes_fuscatus',\n",
       " 'Polistes_metricus',\n",
       " 'Rhipicephalus_appendiculatus',\n",
       " 'Rhipicephalus_microplus',\n",
       " 'Rhipicephalus_sanguineus',\n",
       " 'Rhipicephalus_zambeziensis',\n",
       " 'Rhizoglyphus_robini',\n",
       " 'Solenopsis_invicta',\n",
       " 'Spalangia_endius',\n",
       " 'Temnothorax_ambiguus',\n",
       " 'Temnothorax_curvispinosus',\n",
       " 'Temnothorax_duloticus',\n",
       " 'Temnothorax_longispinosus',\n",
       " 'Temnothorax_pilagens',\n",
       " 'Tetranychus_cinnabarinus',\n",
       " 'Tetranychus_urticae',\n",
       " 'Trichogramma_chilonis',\n",
       " 'Trichogramma_pretiosum',\n",
       " 'Trichomalopsis_sarcophagae',\n",
       " 'Varroa_destructor',\n",
       " 'Varroa_jacobsoni',\n",
       " 'Wasmannia_auropunctata']"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zM0yVXe_GG55"
   },
   "source": [
    "Using a ```for``` loop we can go through each of these names one by one and run all the data cleaning steps.\n",
    "\n",
    "This is exactly the same code as we used for a single table - I have just moved it all into one cell to make it easier to run the loop.\n",
    "\n",
    "I have added two extra lines so that we can combine all the single row summary tables into one long table for all species.\n",
    "\n",
    "I also added one extra step - where there are more than 10,000 records we take a random sample of 10,000 - otherwise the georeferencing step takes too long.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17939,
     "status": "ok",
     "timestamp": 1596110124869,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "RJowWXj73G60",
    "outputId": "874fa4c7-0ffa-44d2-a52b-320c1f72302e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning - the species column for Temnothorax_duloticus has multiple values\n"
     ]
    }
   ],
   "source": [
    "# create an empty DataFrame to store all the summary table rows\n",
    "all_summary_tables = pd.DataFrame()\n",
    "\n",
    "# run everything for every species in the list\n",
    "for species_name in species_list:\n",
    "      # Everything in this indented section will run once for each species name\n",
    "\n",
    "      # Read the input table from GBIF into Python.\n",
    "      mytab = pd.read_csv(file_path + \"/species_tables/\" + species_name + \".csv\", sep=\"\\t\")\n",
    "\n",
    "      # Make a \"summary\" table to record information about the data as we go along.\n",
    "      # Create an empty dataframe with these columns and with one row for this species\n",
    "      summary = pd.DataFrame(columns=['nrecords_unfiltered', 'species', 'genus', 'family', 'order', 'class', 'phylum', 'kingdom', 'wrong_taxon_rank_count',\n",
    "                                      'no_country_code_count', 'no_latlong_count', 'total_removed_data_cleaning', 'nrecords_clean', 'nrecords_after_data_cleaning'],\n",
    "                            index=[species_name])\n",
    "      # Count the number of records for this species in the unfiltered input table\n",
    "      # Record this information in the summary table and write it to the log file.\n",
    "\n",
    "      nrecords = len(mytab)\n",
    "      summary.loc[species_name, 'nrecords_unfiltered'] = nrecords\n",
    "\n",
    "      # Count the number of unique values in the “kingdom”, “phylum”, “class”, “order”, “family”, “genus” and “species” columns - there should only be one in each.\n",
    "      # Print a warning if there is more than one.\n",
    "      # I have removed some of the print statements here just to reduce the amount of output\n",
    "\n",
    "      # if there is only one kingdom for all the rows\n",
    "      if mytab['kingdom'].nunique() == 1:\n",
    "        # record the first value in the kingdom column (as they are all the same)\n",
    "        kingdom = mytab['kingdom'].values[0]\n",
    "      # if there is > 1\n",
    "      else:\n",
    "        # write this message to the log file\n",
    "        print(\"Warning - the kingdom column for %s has multiple values\" % species_name)\n",
    "        # record the kingdom for this species as \"NA\"\n",
    "        kingdom = \"NA\"\n",
    "      summary.loc[species_name, \"kingdom\"] = kingdom\n",
    "\n",
    "      # repeat for phylum, class, order, family, genus, species\n",
    "      if mytab['phylum'].nunique() == 1:\n",
    "        phylum = mytab['kingdom'].values[0]\n",
    "      else:\n",
    "        print(\"Warning - the phylum column for %s as multiple values\" % species_name)\n",
    "        phylum = \"NA\"\n",
    "      summary.loc[species_name, \"phylum\"] = phylum\n",
    "\n",
    "      if mytab['class'].nunique() == 1:\n",
    "        clas = mytab['class'].values[0]\n",
    "      else:\n",
    "        print(\"Warning - the class column for %s has multiple values\" % species_name)\n",
    "        clas = \"NA\"\n",
    "      summary.loc[species_name, \"class\"] = clas\n",
    "\n",
    "      if mytab['order'].nunique() == 1:\n",
    "        order = mytab['order'].values[0]\n",
    "      else:\n",
    "        print(\"Warning - the order column for %s has multiple values\" % species_name)\n",
    "        order = \"NA\"\n",
    "      summary.loc[species_name, \"order\"] = order\n",
    "\n",
    "      if mytab['family'].nunique() == 1:\n",
    "        family = mytab['family'].values[0]\n",
    "      else:\n",
    "        print(\"Warning - the family column for %s has multiple values\" % species_name)\n",
    "        family = \"NA\"\n",
    "      summary.loc[species_name, \"family\"] = family\n",
    "\n",
    "      if mytab['genus'].nunique() == 1:\n",
    "        genus = mytab['genus'].values[0]\n",
    "      else:\n",
    "        print (\"Warning - the genus column for %s has multiple values\" % species_name)\n",
    "        genus = \"NA\"\n",
    "      summary.loc[species_name, \"genus\"] = genus\n",
    "\n",
    "      if mytab['species'].nunique() == 1:\n",
    "        species = mytab['species'].values[0]\n",
    "      else:\n",
    "        print(\"Warning - the species column for %s has multiple values\" % species_name)\n",
    "        species = \"NA\"\n",
    "      summary.loc[species_name, \"species\"] = species\n",
    "\n",
    "\n",
    "      filtered_tab_subspecies_only = mytab[mytab[\"taxonRank\"] == \"SUBSPECIES\"]\n",
    "      filtered_tab_subspecies_only.to_csv(file_path + \"/subspecies_tables/\" + species_name + \".csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "      # count how many rows in the unfiltered table have something other than species in this column\n",
    "      count_wrong_taxon_rank = len(mytab[mytab['taxonRank'] != \"SPECIES\"])\n",
    "      # record this count in the summary table\n",
    "      summary.loc[species_name, \"wrong_taxon_rank_count\"] = count_wrong_taxon_rank\n",
    "\n",
    "      # In the taxonRank column, some records are classified as “SPECIES” and some as SUBSPECIES”.\n",
    "      # Subspecies is a more specific classification - some researchers will be able to recognise and record different subspecies and others will not. \n",
    "      # For now, we will focus on the “SPECIES” records because there are more of them.\n",
    "\n",
    "      # Create and save a smaller table of individuals with “SUBSPECIES” in this column.\n",
    "\n",
    "      # Remove these individuals from the main table - filter it to keep only records where taxonRank == “SPECIES”.\n",
    "\n",
    "      # filter out all rows which don't have \"SPECIES\" in this column\n",
    "      mytab = mytab[mytab[\"taxonRank\"] == \"SPECIES\"]\n",
    "\n",
    "      # Create and save a smaller table of samples with no value in the “countryCode” column\n",
    "      # then remove these individuals from the main table.\n",
    "\n",
    "      filtered_table_null = mytab[mytab['countryCode'].isnull()]\n",
    "      filtered_table_null.to_csv(file_path + \"/species_tables_null/\" + species_name + \".csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "      # count how many rows have no country code\n",
    "      count_no_country_code = len(mytab[mytab['countryCode'].isnull()])\n",
    "      summary.loc[species_name, \"no_country_code_count\"] = count_no_country_code\n",
    "\n",
    "      mytab = mytab[mytab['countryCode'].notnull()]\n",
    "\n",
    "      # Remove rows where latitude or longitude is NA\n",
    "      count_no_latlong = len(mytab[(mytab['decimalLatitude'].isnull()) | (mytab['decimalLongitude'].isnull())])\n",
    "      summary.loc[species_name, 'no_latlong_count'] = count_no_latlong\n",
    "\n",
    "      mytab = mytab[mytab['decimalLatitude'].notnull()]\n",
    "      mytab = mytab[mytab['decimalLongitude'].notnull()]\n",
    "\n",
    "      # We can now count the total number of rows which have been filtered out and add it to the summary table.\n",
    "      total_removed = count_wrong_taxon_rank + count_no_country_code + count_no_latlong\n",
    "      summary.loc[species_name, 'total_removed_data_cleaning'] = total_removed\n",
    "\n",
    "      # The last data cleaning step is to add the total number of rows removed in this \n",
    "      # stage to the summary table.\n",
    "      summary.loc[species_name, \"nrecords_clean\"] = len(mytab)\n",
    "\n",
    "      # If there are more than 10000 rows in the clean dataframe take a random\n",
    "      # sample of 10000 rows\n",
    "      if len(mytab) > 10000:\n",
    "        mytab = mytab.sample(10000)\n",
    "\n",
    "      summary.loc[species_name, \"nrecords_after_data_cleaning\"] = len(mytab)\n",
    "      # Finally, we save the filtered table and the summary table.\n",
    "      mytab.to_csv(file_path + \"/filtered_main_tables/\" + species_name + \".csv\", sep=\"\\t\", index=None)\n",
    "      summary.to_csv(file_path + \"/summary_tables/\" + species_name + \".csv\", sep=\"\\t\")\n",
    "\n",
    "      # add the summary to the big summary table\n",
    "      all_summary_tables = all_summary_tables.append(summary)\n",
    "\n",
    "# save the big summary table\n",
    "all_summary_tables['species_name'] = all_summary_tables.index.values\n",
    "all_summary_tables.to_csv(file_path + \"final_summary_data_cleaning.tsv\", sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1596114565131,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "iI2Ho5jKSdqK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J7U9hkILfo7m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOKJ0pmqgJS9vZuUZkAWGUn",
   "collapsed_sections": [],
   "name": "Data_Cleaning_Batch",
   "provenance": [
    {
     "file_id": "1JCagcN5sKQdf8OvgrxerPOcpDiTURygr",
     "timestamp": 1596103584412
    },
    {
     "file_id": "1vhDRNO8Ov_4I3V0wjyGdSv5qZd28P26R",
     "timestamp": 1596016780263
    },
    {
     "file_id": "1fgK0oP7jFP4z2krdH0pKzR--BtjpzyLs",
     "timestamp": 1595944079107
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
