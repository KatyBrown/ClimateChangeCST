{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42597,
     "status": "ok",
     "timestamp": 1597157778503,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "RPOPpqEXohJO",
    "outputId": "62d78cf6-436e-43bc-94af-cda234acc9d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "libgeos-dev is already the newest version (3.6.2-1build2).\n",
      "libproj-dev is already the newest version (4.9.3-2).\n",
      "proj-bin is already the newest version (4.9.3-2).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
      "  Building wheel for basemap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "!pip install -q geopandas\n",
    "!apt install -q proj-bin libproj-dev libgeos-dev -y\n",
    "!pip install -q https://github.com/matplotlib/basemap/archive/master.zip\n",
    "!pip install -q rasterio\n",
    "\n",
    "# Pandas is a package containing additional functions to use data frames in Python\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import warnings\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "warnings.simplefilter('ignore')\n",
    "# These two lines allow the notebook to access the Google Drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# This is the path to the project folder within the Google Drive.\n",
    "file_path = \"/content/drive/My Drive/\"\n",
    "import rpy2.interactive\n",
    "\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "from rpy2.robjects import pandas2ri  # activate pandas R  interface\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4bpBxLAg-vL"
   },
   "source": [
    "Here we load some packages in another programming language - R. We won't use this language very much (because I prefer Python), but we will briefly switch languages to run the model because the tool to run it requires this language.\n",
    "\n",
    "Running this cell might take a a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 184978,
     "status": "ok",
     "timestamp": 1597157920899,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "mJSVhN6VfyPc",
    "outputId": "6c832c3a-d20c-4794-be1e-b2ac2e0e0d64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: rgeos version: 0.5-3, (SVN revision 634)\n",
      " GEOS runtime version: 3.6.2-CAPI-1.10.2 \n",
      " Linking to sp version: 1.4-2 \n",
      " Polygon checking: TRUE \n",
      "\n",
      "\n",
      "R[write to console]: Checking rgeos availability: TRUE\n",
      "\n"
     ]
    }
   ],
   "source": [
    " %%R\n",
    "install.packages('rgeos', quiet=TRUE)\n",
    "install.packages('raster', quiet=TRUE)\n",
    "install.packages('rgdal', quiet=TRUE)\n",
    "install.packages('maptools', quiet=TRUE)\n",
    "install.packages('dismo', quiet=TRUE)\n",
    "\n",
    "require('rgdal', quiet=TRUE)\n",
    "require('rgeos', quiet=TRUE)\n",
    "require('maptools', quiet=TRUE)\n",
    "require('dismo', quiet=TRUE)\n",
    "require('raster', quiet=TRUE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 189719,
     "status": "ok",
     "timestamp": 1597157925655,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "Dh3zkWtFaJz5",
    "outputId": "76ed0140-b95c-4436-bd8b-ca78ef55ed62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: randomForest 4.6-14\n",
      "\n",
      "R[write to console]: Type rfNews() to see new features/changes/bug fixes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "install.packages('randomForest', quiet=TRUE)\n",
    "require('randomForest', quiet=TRUE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 189704,
     "status": "ok",
     "timestamp": 1597157925658,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "agh9gxiuuUYX"
   },
   "outputs": [],
   "source": [
    "def convert_xy_to_longlat(grid_x, grid_y):\n",
    "  lon = ((grid_x / 6) - 180)\n",
    "  lat = -((grid_y / 6) - 90)\n",
    "  return (lon, lat)\n",
    "\n",
    "def convert_longlat_to_xy(lon, lat):\n",
    "  grid_x = int((lon + 180) * 6)\n",
    "  grid_y = int((-lat + 90) * 6)\n",
    "  return (grid_x, grid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 189694,
     "status": "ok",
     "timestamp": 1597157925660,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "1tgiitJj_c62"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76aJVPvsucVA"
   },
   "source": [
    "---\n",
    "## Notebook 15\n",
    "# Applying Species Distribution Models - Automated\n",
    "In this notebook we repeat the code from notebook 14 but it is run on every species and on every combination of models, ssps and time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4615852,
     "status": "ok",
     "timestamp": 1597196601883,
     "user": {
      "displayName": "Katy Brown",
      "photoUrl": "",
      "userId": "04725673548216289527"
     },
     "user_tz": -60
    },
    "id": "j062P0AvzfHM",
    "outputId": "8f665f3d-9c7a-4266-ddcf-ac01d2b4758f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ceratina_australensis\n",
      "Rhizoglyphus_robini\n",
      "Solenopsis_invicta\n",
      "Importing data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Importing data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Importing data for CanESM5 ssp126 2021-2040\n",
      "Exporting data for CanESM5 ssp126 2021-2040\n",
      "Importing data for CanESM5 ssp126 2041-2060\n",
      "Exporting data for CanESM5 ssp126 2041-2060\n",
      "Importing data for CanESM5 ssp126 2061-2080\n",
      "Exporting data for CanESM5 ssp126 2061-2080\n",
      "Importing data for CanESM5 ssp126 2081-2100\n",
      "Exporting data for CanESM5 ssp126 2081-2100\n",
      "Importing data for CanESM5 ssp585 2021-2040\n",
      "Exporting data for CanESM5 ssp585 2021-2040\n",
      "Importing data for CanESM5 ssp585 2041-2060\n",
      "Exporting data for CanESM5 ssp585 2041-2060\n",
      "Importing data for CanESM5 ssp585 2061-2080\n",
      "Exporting data for CanESM5 ssp585 2061-2080\n",
      "Importing data for CanESM5 ssp585 2081-2100\n",
      "Exporting data for CanESM5 ssp585 2081-2100\n",
      "Spalangia_endius\n",
      "Temnothorax_ambiguus\n",
      "Importing data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Importing data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Importing data for CanESM5 ssp126 2021-2040\n",
      "Exporting data for CanESM5 ssp126 2021-2040\n",
      "Importing data for CanESM5 ssp126 2041-2060\n",
      "Exporting data for CanESM5 ssp126 2041-2060\n",
      "Importing data for CanESM5 ssp126 2061-2080\n",
      "Exporting data for CanESM5 ssp126 2061-2080\n",
      "Importing data for CanESM5 ssp126 2081-2100\n",
      "Exporting data for CanESM5 ssp126 2081-2100\n",
      "Importing data for CanESM5 ssp585 2021-2040\n",
      "Exporting data for CanESM5 ssp585 2021-2040\n",
      "Importing data for CanESM5 ssp585 2041-2060\n",
      "Exporting data for CanESM5 ssp585 2041-2060\n",
      "Importing data for CanESM5 ssp585 2061-2080\n",
      "Exporting data for CanESM5 ssp585 2061-2080\n",
      "Importing data for CanESM5 ssp585 2081-2100\n",
      "Exporting data for CanESM5 ssp585 2081-2100\n",
      "Temnothorax_curvispinosus\n",
      "Importing data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Importing data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Importing data for CanESM5 ssp126 2021-2040\n",
      "Exporting data for CanESM5 ssp126 2021-2040\n",
      "Importing data for CanESM5 ssp126 2041-2060\n",
      "Exporting data for CanESM5 ssp126 2041-2060\n",
      "Importing data for CanESM5 ssp126 2061-2080\n",
      "Exporting data for CanESM5 ssp126 2061-2080\n",
      "Importing data for CanESM5 ssp126 2081-2100\n",
      "Exporting data for CanESM5 ssp126 2081-2100\n",
      "Importing data for CanESM5 ssp585 2021-2040\n",
      "Exporting data for CanESM5 ssp585 2021-2040\n",
      "Importing data for CanESM5 ssp585 2041-2060\n",
      "Exporting data for CanESM5 ssp585 2041-2060\n",
      "Importing data for CanESM5 ssp585 2061-2080\n",
      "Exporting data for CanESM5 ssp585 2061-2080\n",
      "Importing data for CanESM5 ssp585 2081-2100\n",
      "Exporting data for CanESM5 ssp585 2081-2100\n",
      "Temnothorax_duloticus\n",
      "Temnothorax_longispinosus\n",
      "Importing data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Importing data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Importing data for CanESM5 ssp126 2021-2040\n",
      "Exporting data for CanESM5 ssp126 2021-2040\n",
      "Importing data for CanESM5 ssp126 2041-2060\n",
      "Exporting data for CanESM5 ssp126 2041-2060\n",
      "Importing data for CanESM5 ssp126 2061-2080\n",
      "Exporting data for CanESM5 ssp126 2061-2080\n",
      "Importing data for CanESM5 ssp126 2081-2100\n",
      "Exporting data for CanESM5 ssp126 2081-2100\n",
      "Importing data for CanESM5 ssp585 2021-2040\n",
      "Exporting data for CanESM5 ssp585 2021-2040\n",
      "Importing data for CanESM5 ssp585 2041-2060\n",
      "Exporting data for CanESM5 ssp585 2041-2060\n",
      "Importing data for CanESM5 ssp585 2061-2080\n",
      "Exporting data for CanESM5 ssp585 2061-2080\n",
      "Importing data for CanESM5 ssp585 2081-2100\n",
      "Exporting data for CanESM5 ssp585 2081-2100\n",
      "Temnothorax_pilagens\n",
      "Tetranychus_cinnabarinus\n",
      "Tetranychus_urticae\n",
      "Importing data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Importing data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Importing data for CanESM5 ssp126 2021-2040\n",
      "Exporting data for CanESM5 ssp126 2021-2040\n",
      "Importing data for CanESM5 ssp126 2041-2060\n",
      "Exporting data for CanESM5 ssp126 2041-2060\n",
      "Importing data for CanESM5 ssp126 2061-2080\n",
      "Exporting data for CanESM5 ssp126 2061-2080\n",
      "Importing data for CanESM5 ssp126 2081-2100\n",
      "Exporting data for CanESM5 ssp126 2081-2100\n",
      "Importing data for CanESM5 ssp585 2021-2040\n",
      "Exporting data for CanESM5 ssp585 2021-2040\n",
      "Importing data for CanESM5 ssp585 2041-2060\n",
      "Exporting data for CanESM5 ssp585 2041-2060\n",
      "Importing data for CanESM5 ssp585 2061-2080\n",
      "Exporting data for CanESM5 ssp585 2061-2080\n",
      "Importing data for CanESM5 ssp585 2081-2100\n",
      "Exporting data for CanESM5 ssp585 2081-2100\n",
      "Trichogramma_chilonis\n",
      "Trichogramma_pretiosum\n",
      "Trichomalopsis_sarcophagae\n",
      "Varroa_destructor\n",
      "Importing data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Importing data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Importing data for CanESM5 ssp126 2021-2040\n",
      "Exporting data for CanESM5 ssp126 2021-2040\n",
      "Importing data for CanESM5 ssp126 2041-2060\n",
      "Exporting data for CanESM5 ssp126 2041-2060\n",
      "Importing data for CanESM5 ssp126 2061-2080\n",
      "Exporting data for CanESM5 ssp126 2061-2080\n",
      "Importing data for CanESM5 ssp126 2081-2100\n",
      "Exporting data for CanESM5 ssp126 2081-2100\n",
      "Importing data for CanESM5 ssp585 2021-2040\n",
      "Exporting data for CanESM5 ssp585 2021-2040\n",
      "Importing data for CanESM5 ssp585 2041-2060\n",
      "Exporting data for CanESM5 ssp585 2041-2060\n",
      "Importing data for CanESM5 ssp585 2061-2080\n",
      "Exporting data for CanESM5 ssp585 2061-2080\n",
      "Importing data for CanESM5 ssp585 2081-2100\n",
      "Exporting data for CanESM5 ssp585 2081-2100\n",
      "Varroa_jacobsoni\n",
      "Wasmannia_auropunctata\n",
      "Importing data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp126 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp126 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp126 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp126 2081-2100\n",
      "Importing data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Exporting data for BCC-CSM2-MR ssp585 2021-2040\n",
      "Importing data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Exporting data for BCC-CSM2-MR ssp585 2041-2060\n",
      "Importing data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Exporting data for BCC-CSM2-MR ssp585 2061-2080\n",
      "Importing data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Exporting data for BCC-CSM2-MR ssp585 2081-2100\n",
      "Importing data for CanESM5 ssp126 2021-2040\n",
      "Exporting data for CanESM5 ssp126 2021-2040\n",
      "Importing data for CanESM5 ssp126 2041-2060\n",
      "Exporting data for CanESM5 ssp126 2041-2060\n",
      "Importing data for CanESM5 ssp126 2061-2080\n",
      "Exporting data for CanESM5 ssp126 2061-2080\n",
      "Importing data for CanESM5 ssp126 2081-2100\n",
      "Exporting data for CanESM5 ssp126 2081-2100\n",
      "Importing data for CanESM5 ssp585 2021-2040\n",
      "Exporting data for CanESM5 ssp585 2021-2040\n",
      "Importing data for CanESM5 ssp585 2041-2060\n",
      "Exporting data for CanESM5 ssp585 2041-2060\n",
      "Importing data for CanESM5 ssp585 2061-2080\n",
      "Exporting data for CanESM5 ssp585 2061-2080\n",
      "Importing data for CanESM5 ssp585 2081-2100\n",
      "Exporting data for CanESM5 ssp585 2081-2100\n"
     ]
    }
   ],
   "source": [
    "species_list = [line.strip() for line in open(file_path + \"species_names.tsv\")]\n",
    "models = ['BCC-CSM2-MR',\n",
    "         'CanESM5']\n",
    "scenarios = ['ssp126', 'ssp585']\n",
    "\n",
    "time_periods = ['2021-2040', '2041-2060', '2061-2080', '2081-2100']\n",
    "\n",
    "this_boundary = [((0, 2160)), ((930, 0))]\n",
    "\n",
    "# make a dictionary of bioclim variable names for convinence\n",
    "bioclim = pd.read_csv(file_path + \"bioclim.tsv\", sep=\"\\t\")\n",
    "bioclim_name = dict(zip(bioclim['variable_number'], bioclim['name']))\n",
    "\n",
    "# make a list of bioclim variables \n",
    "bc = list(bioclim_name.values())\n",
    "\n",
    "for species_name in species_list:\n",
    "      if not os.path.exists(file_path + \"SDM_results/\" + species_name):\n",
    "        os.mkdir(file_path + \"SDM_results/\" + species_name)\n",
    "        print (species_name)\n",
    "        if os.path.exists(file_path + \"species_plus_climate_observed_geo/\" + species_name + \".tsv\"):\n",
    "          # read the presence data\n",
    "          presence_table = pd.read_csv(file_path + \"species_plus_climate_observed_geo/\" + species_name + \".tsv\", sep=\"\\t\")\n",
    "\n",
    "          if len(presence_table) > 50:\n",
    "            # add a column to show these points are where the species is present\n",
    "            presence_table['p'] = 1\n",
    "\n",
    "            # read the absence data\n",
    "            try:\n",
    "              absence_table = pd.read_csv(file_path + \"species_plus_climate_observed_absence/\" + species_name + \"_geo.tsv\", sep=\"\\t\")\n",
    "            except:\n",
    "              continue\n",
    "            absence_table['p'] = 0\n",
    "            # Calculate the sample size for the presence and absence data - 5% of the total number of records\n",
    "            sample_size_presence = int(len(presence_table) * 0.05)\n",
    "            sample_size_absence = int(len(absence_table) * 0.05)\n",
    "\n",
    "            # take a random 5% of observation IDs for the presence data\n",
    "            sample_presence = np.random.choice(presence_table['obs_ID'], sample_size_presence)\n",
    "\n",
    "            # take a random 5% of observation IDs for the absence data\n",
    "            sample_absence = np.random.choice(absence_table['obs_ID'], sample_size_absence)\n",
    "\n",
    "            # extract the 5% of samples for testing\n",
    "            training_presence = presence_table[~presence_table['obs_ID'].isin(sample_presence)]\n",
    "            training_absence = absence_table[~absence_table['obs_ID'].isin(sample_absence)]\n",
    "\n",
    "\n",
    "            # extract the 95% of samples for training\n",
    "            testing_presence = presence_table[presence_table['obs_ID'].isin(sample_presence)]\n",
    "            testing_absence = absence_table[absence_table['obs_ID'].isin(sample_absence)]\n",
    "\n",
    "            # combine the testing and training data for presence and absence\n",
    "            testing_combined = testing_presence.append(testing_absence)\n",
    "            training_combined = training_presence.append(training_absence)\n",
    "\n",
    "            # remove the extra columns (with non-climate data e.g. latitude and longitude)\n",
    "            # from the testing and training tables\n",
    "            testing_combined = testing_combined[list(bioclim_name.values()) + ['p']].astype(float)\n",
    "            training_combined = training_combined[list(bioclim_name.values()) + ['p']].astype(float)\n",
    "            # set the paths to the raster files for current and predicted climate\n",
    "            raster_path_current = file_path + \"climate_data/\" + \"near_present.tif\"\n",
    "\n",
    "            raster_current = rasterio.open(raster_path_current)\n",
    "            # convert the data into a matrix, round to 6dp, replace inf with nan\n",
    "            grid_current = raster_current.read()\n",
    "            grid_current = np.round(grid_current, 6)\n",
    "            grid_current[grid_current == float('-inf'), ] = float('nan')\n",
    "            # exclude very low latitudes\n",
    "            gc = grid_current[:, this_boundary[1][1]:this_boundary[1][0], this_boundary[0][0]:this_boundary[0][1]]\n",
    "\n",
    "            # pass the dataframes in to R\n",
    "            %R -i testing_combined\n",
    "            %R -i training_combined\n",
    "\n",
    "            # pass the list of Bioclim variables into R\n",
    "            %R -i bc\n",
    "          # make an empty R raster object\n",
    "            %R raster_current = raster()\n",
    "\n",
    "            # for each layer of the raster grid\n",
    "            for i in np.arange(0, 19, 1):\n",
    "                # extract a single layer from the Python raster\n",
    "                grid_current = gc[i]\n",
    "                # pass the layer to R\n",
    "                %R -i grid_current\n",
    "                # convert to a matrix\n",
    "                %R grid_matrix_current = as.matrix(grid_current)\n",
    "\n",
    "                # find the minimum and maximum dimensions\n",
    "                %R xmax_current = dim(grid_current)[1]\n",
    "                %R ymax_current = dim(grid_current)[2]\n",
    "\n",
    "                # convert to an R raster layer\n",
    "                %R this_grid_current_raster = raster(grid_matrix_current, xmn=0, xmx=xmax_current, ymn=0, ymx=ymax_current, template=NULL)\n",
    "                # add the layer to the big R raster\n",
    "                %R raster_current = addLayer(raster_current, this_grid_current_raster)\n",
    "\n",
    "\n",
    "            # name the layers of the R raster using the Bioclim variable names\n",
    "            %R names(raster_current) = bc\n",
    "\n",
    "            # make copies of all the testing tables without the presence / absence column\n",
    "            testing_presence_bc = testing_presence[bc]\n",
    "            testing_absence_bc = testing_absence[bc]\n",
    "            training_presence_bc = training_presence[bc]\n",
    "            testing_combined_bc = testing_combined[bc]\n",
    "\n",
    "            # pass all the tables into R\n",
    "            %R -i testing_presence_bc\n",
    "            %R -i testing_absence_bc\n",
    "            %R -i training_presence_bc\n",
    "            %R -i testing_combined_bc\n",
    "            %R bc = unlist(bc)\n",
    "            # Create a GLM model based on the training data\n",
    "            %R glm_model = glm(p ~ . , data=training_combined, family=binomial(logit))\n",
    "\n",
    "            # Create a Bioclim model based on the training data\n",
    "            %R bioclim_model = bioclim(training_presence_bc)\n",
    "\n",
    "            # for Bioclim we also need to find a threshold to assign species as present or absent\n",
    "            %R e_bioclim = evaluate(testing_presence_bc, testing_absence_bc, bioclim_model)\n",
    "            %R t_bioclim <- threshold(e_bioclim, 'spec_sens')\n",
    "\n",
    "            # Create a random forest model based on the training data\n",
    "            %R rf_model = randomForest(factor(p) ~ ., data=training_combined)\n",
    "\n",
    "\n",
    "            # predict presence or absence for the test data using the GLM model\n",
    "            %R glm_test = predict(glm_model, testing_combined_bc, type='response') > 0.5\n",
    "\n",
    "            # predict presence or absence for the test data using the Bioclim Model\n",
    "            %R bioclim_test = predict(bioclim_model, testing_combined_bc) > t_bioclim\n",
    "\n",
    "            # predict presence or absence for the test data using the random forest model\n",
    "            %R rf_test = predict(rf_model, testing_combined_bc)\n",
    "\n",
    "            %R -o glm_test\n",
    "            %R -o bioclim_test\n",
    "            %R -o rf_test\n",
    "            %R -o t_bioclim\n",
    "            testing_combined['test_result_glm'] = glm_test\n",
    "            testing_combined['test_result_bioclim'] = bioclim_test\n",
    "            testing_combined['test_result_rf'] = rf_test.astype(int) \n",
    "\n",
    "            # Count how many times the model correctly predicted presence or absence for the test data\n",
    "            total_correct_glm = sum(testing_combined['test_result_glm'] == testing_combined['p'])\n",
    "            total_correct_bioclim = sum(testing_combined['test_result_bioclim'] == testing_combined['p'])\n",
    "            total_correct_rf = sum(testing_combined['test_result_rf'] == testing_combined['p'])\n",
    "\n",
    "            # convert these to percentages\n",
    "            percent_correct_glm = round((total_correct_glm / len(testing_combined)) * 100, 2)\n",
    "            percent_correct_bioclim = round((total_correct_bioclim / len(testing_combined)) * 100, 2)\n",
    "            percent_correct_rf = round((total_correct_rf / len(testing_combined)) * 100, 2)\n",
    "\n",
    "\n",
    "            testing_combined.to_csv(file_path + \"SDM_results/\" + species_name + \"testing.tsv\", sep=\"\\t\", index=None)\n",
    "            # Predict current habitable areas under the glm model\n",
    "            %R res_glm = predict(raster_current, glm_model, type='response')\n",
    "            %R res_glm = as.matrix(res_glm[[1]])\n",
    "\n",
    "            # Predict current habitable areas under the bioclim model\n",
    "            %R res_bioclim = predict(raster_current, bioclim_model)\n",
    "            %R res_bioclim = as.matrix(res_bioclim[[1]])\n",
    "\n",
    "            # Predict current habitable areas under the random forest model\n",
    "            %R res_rf = predict(raster_current, rf_model)\n",
    "            %R res_rf = as.matrix(res_rf[[1]])\n",
    "\n",
    "            %R -o res_glm\n",
    "            %R -o res_bioclim\n",
    "            %R -o res_rf\n",
    "\n",
    "            D = dict()\n",
    "\n",
    "            D['present_glm'] = res_glm\n",
    "            D['present_bioclim'] = res_bioclim\n",
    "            D['present_rf'] = res_rf\n",
    "\n",
    "            for key in D:\n",
    "              # make sure all the values are floats\n",
    "              D[key] = D[key].astype('float')\n",
    "\n",
    "              # fill in NA where appropriate\n",
    "              D[key][D[key] < 0] = float('nan')\n",
    "              if \"glm\" in key:\n",
    "                # glm predictions should be normalised to 0 or 1\n",
    "                D[key][D[key] > 0.5] = 1\n",
    "                D[key][(D[key] < 0.5) & (D[key] > 0)] = 0\n",
    "              elif \"bioclim\" in key:\n",
    "                # bioclim predictions should be assigned using the bioclim threshold\n",
    "                D[key][D[key] > t_bioclim] = 1\n",
    "                D[key][(D[key] < t_bioclim) & (D[key] > 0)] = 0\n",
    "\n",
    "\n",
    "            np.save(file_path + \"SDM_results/\" + species_name + \"/\" + \"present_glm.npy\", D['present_glm'])\n",
    "            np.save(file_path + \"SDM_results/\" + species_name + \"/\" + \"present_bioclim.npy\", D['present_bioclim'])\n",
    "            np.save(file_path + \"SDM_results/\" + species_name + \"/\" + \"present_rf.npy\", D['present_rf'])\n",
    "            for model_future in models:\n",
    "              for ssp_future in scenarios:\n",
    "                for timepoint_future in time_periods:\n",
    "                  D2 = dict()\n",
    "                  # Print a message so we know it's still running\n",
    "                  print (\"Importing data for %s %s %s\" % (model_future, ssp_future, timepoint_future))\n",
    "\n",
    "                  # generate the path to the raster data\n",
    "                  raster_path_future = file_path + \"climate_data/\" + model_future + \"/\" + ssp_future + \"/\" + timepoint_future + \".tiff\"\n",
    "\n",
    "                  # read the raster into Python and tidy it up\n",
    "                  raster_future = rasterio.open(raster_path_future)\n",
    "                  grid_future = raster_future.read()\n",
    "                  grid_future = np.round(grid_future, 6)\n",
    "                  grid_future[grid_future == float('-inf'), ] = float('nan')\n",
    "                  # exclude very low latitudes\n",
    "                  gf = grid_future[:, this_boundary[1][1]:this_boundary[1][0], this_boundary[0][0]:this_boundary[0][1]]\n",
    "\n",
    "                  # generate an empty R raster\n",
    "                  %R raster_future = raster()\n",
    "                  # for each layer of the Python raster\n",
    "                  for i in range(0, 19):\n",
    "                      # extract the current layer from the Python raster\n",
    "                      grid_future = gf[i]\n",
    "\n",
    "                      # pass the layer into R\n",
    "                      %R -i grid_future\n",
    "                      # convert to a matrix\n",
    "                      %R grid_matrix_future = as.matrix(grid_future)\n",
    "\n",
    "                      # find the minimum and maximum dimensions\n",
    "                      %R xmax_future = dim(grid_future)[1]\n",
    "                      %R ymax_future = dim(grid_future)[2]\n",
    "\n",
    "                      # convert to an R raster layer\n",
    "                      %R this_grid_future_raster = raster(grid_matrix_future, xmn=0, xmx=xmax_future, ymn=0, ymx=ymax_future, template=NULL)\n",
    "                      # add the layer to the big R raster\n",
    "                      %R raster_future = addLayer(raster_future, this_grid_future_raster)\n",
    "                  # rename the R raster layers using the R variable names\n",
    "                  %R names(raster_future) = bc\n",
    "                  print (\"Exporting data for %s %s %s\" % (model_future, ssp_future, timepoint_future)) \n",
    "\n",
    "\n",
    "                  # predict the habitable area using the GLM model\n",
    "                  %R res_glmx = predict(raster_future, glm_model, type='response')\n",
    "                  %R res_glmx = as.matrix(res_glmx[[1]])\n",
    "\n",
    "                  # predict the habitable area using the bioclim model\n",
    "                  %R res_bioclimx = predict(raster_future, bioclim_model)\n",
    "                  %R res_bioclimx = as.matrix(res_bioclimx[[1]])\n",
    "\n",
    "                  # predict the habitable area using the random forest model\n",
    "                  %R res_rfx = predict(raster_future, rf_model)\n",
    "                  %R res_rfx = as.matrix(res_rfx[[1]])\n",
    "\n",
    "                  # output everything back to Python\n",
    "                  %R -o res_glmx\n",
    "                  %R -o res_bioclimx\n",
    "                  %R -o res_rfx\n",
    "                  subnam = model_future + \"_\" + ssp_future + \"_\" + timepoint_future + \"_\"\n",
    "                  D2[subnam + \"_glm\"] = res_glmx\n",
    "                  D2[subnam + \"_bioclim\"] = res_bioclimx\n",
    "                  D2[subnam + \"_rf\"] = res_rfx \n",
    "                  for key in D2:\n",
    "                    # make sure all the values are floats\n",
    "                    D2[key] = D2[key].astype('float')\n",
    "\n",
    "                    # fill in NA where appropriate\n",
    "                    D2[key][D2[key] < 0] = float('nan')\n",
    "                    if \"glm\" in key:\n",
    "                      # glm predictions should be normalised to 0 or 1\n",
    "                      D2[key][D2[key] > 0.5] = 1\n",
    "                      D2[key][(D2[key] < 0.5) & (D2[key] > 0)] = 0\n",
    "                    elif \"bioclim\" in key:\n",
    "                      # bioclim predictions should be assigned using the bioclim threshold\n",
    "                      D2[key][D2[key] > t_bioclim] = 1\n",
    "                      D2[key][(D2[key] < t_bioclim) & (D2[key] > 0)] = 0\n",
    "\n",
    "                  np.save(file_path + \"SDM_results/\" + species_name + \"/\" + subnam +  \"_glm.npy\", D2[subnam + '_glm'])\n",
    "                  np.save(file_path + \"SDM_results/\" + species_name + \"/\" + subnam + \"_bioclim.npy\", D2[subnam + '_bioclim'])\n",
    "                  np.save(file_path + \"SDM_results/\" + species_name + \"/\" + subnam + \"_rf.npy\", D2[subnam + '_rf'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyfV6DtFDnGe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNB00ZVsjAqqSneiTyhIS+K",
   "collapsed_sections": [],
   "name": "15_SDMs_batch.ipynb",
   "provenance": [
    {
     "file_id": "1uWsG2WImzB4cAXSyaSjfYy05hJJ7DrcQ",
     "timestamp": 1597153862918
    },
    {
     "file_id": "1rbf23z75cQEZK1cf1J6UzUjONwoNkqta",
     "timestamp": 1597153150848
    },
    {
     "file_id": "1CK3pembU63f-LIHil2CtJltp9GtwBr3y",
     "timestamp": 1596803598953
    },
    {
     "file_id": "1znoNo7JDrfelUOgAYtMYMZpa4T2OWLzt",
     "timestamp": 1596728531288
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
